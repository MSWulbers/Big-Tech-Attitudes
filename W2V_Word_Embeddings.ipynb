{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import scipy\n",
    "import mibian\n",
    "import nltk\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "from nrclex import NRCLex\n",
    "from pyemd import emd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Word Embeddings\n",
    "\n",
    "To re-run the analysis, load your data and name it `gafa_data`.\n",
    "It should entail a `.txt` file with each line containing pre-processed text corresponding to one Reddit comment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "gafa_data = pd.read_csv('working_directory',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty rows\n",
    "gafa_data = gafa_data[gafa_data[0].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentences for W2V model; keep bigrams \n",
    "# as seen in https://www.kaggle.com/pierremegret/gensim-word2vec-tutorial\n",
    "sent = [row.split() for row in gafa_data[0]]\n",
    "phrases = Phrases(sent, min_count=10, progress_per=10000)\n",
    "bigram = Phraser(phrases)\n",
    "sentences = bigram[sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "w2v_model = Word2Vec(sentences, \n",
    "                     min_count=10,\n",
    "                     window=10,\n",
    "                     size=300,\n",
    "                     sg=1,\n",
    "                     workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain word vectors\n",
    "word_vectors = w2v_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cosine similarity between words\n",
    "print(word_vectors.similarity('google', 'amazon'))\n",
    "print(word_vectors.similarity('google', 'facebook'))\n",
    "print(word_vectors.similarity('google', 'apple'))\n",
    "print(word_vectors.similarity('amazon', 'facebook'))\n",
    "print(word_vectors.similarity('amazon', 'apple'))\n",
    "print(word_vectors.similarity('facebook', 'apple'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The word further away from the mean of all word vectors\n",
    "word_vectors.doesnt_match(['google', 'amazon', 'facebook', 'apple'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tme most senamtically similar words\n",
    "google_words = word_vectors.most_similar('google')\n",
    "google_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_words = word_vectors.most_similar('amazon')\n",
    "amazon_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facebook_words = word_vectors.most_similar('facebook')\n",
    "facebook_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_words = word_vectors.most_similar('apple')\n",
    "apple_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_words = word_vectors.most_similar('cambridge_analytica')\n",
    "ca_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarities to Cambridge Analytica\n",
    "print(word_vectors.similarity('google', 'cambridge_analytica'))\n",
    "print(word_vectors.similarity('amazon', 'cambridge_analytica'))\n",
    "print(word_vectors.similarity('facebook', 'cambridge_analytica'))\n",
    "print(word_vectors.similarity('apple', 'cambridge_analytica'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine distances from Cambridge Analytica. I.e. 1 - similarity().\n",
    "print(word_vectors.distances('cambridge_analytica',\n",
    "                ['google','amazon','facebook','apple']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE Plot\n",
    "\n",
    "Plot the 15 most similar words to the words contained in the `keys` list within a 2-dimensional space as seen in https://towardsdatascience.com/google-news-and-leo-tolstoy-visualizing-word2vec-word-embeddings-with-t-sne-11558d8bd4d .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['google','amazon','facebook','apple','cambridge_analytica']\n",
    "\n",
    "embedding_clusters = []\n",
    "word_clusters = []\n",
    "for word in keys:\n",
    "    embeddings = []\n",
    "    words = []\n",
    "    for similar_word, _ in w2v_model.wv.most_similar(word, topn=15):\n",
    "        words.append(similar_word)\n",
    "        embeddings.append(w2v_model.wv[similar_word])\n",
    "    embedding_clusters.append(embeddings)\n",
    "    word_clusters.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_clusters = np.array(embedding_clusters)\n",
    "n, m, k = embedding_clusters.shape\n",
    "tsne_model_en_2d = TSNE(perplexity=15, n_components=2, init='pca', n_iter=3500, random_state=32)\n",
    "embeddings_en_2d = np.array(tsne_model_en_2d.fit_transform(embedding_clusters.reshape(n * m, k))).reshape(n, m, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('classic')\n",
    "plt.rcParams['grid.color'] = 'white'\n",
    "plt.rcParams['legend.fancybox'] = True\n",
    "plt.rcParams['axes.axisbelow'] = False\n",
    "plt.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot_similar_words(title, labels, embedding_clusters, \n",
    "                            word_clusters, a, filename=None):\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    \n",
    "    ax = plt.subplot()\n",
    "    ax.set_xlim(-4, 16)\n",
    "    ax.set_ylim(-20.5,-2.5)\n",
    "    \n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(labels)))\n",
    "    for label, embeddings, words, color in zip(labels, embedding_clusters, word_clusters, colors):\n",
    "        x = embeddings[:, 0]\n",
    "        y = embeddings[:, 1]\n",
    "        plt.scatter(x, y, c=color.reshape(1,-1), alpha=a, label=label, edgecolors='face')\n",
    "        for i, word in enumerate(words):\n",
    "            plt.annotate(word, alpha=0.8, xy=(x[i], y[i]), xytext=(5, 2),\n",
    "                         textcoords='offset points', ha='right', va='bottom', size=12)\n",
    "    plt.legend(loc=4, fontsize = 12)\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.xticks([-2.5,0,2.5,5,7.5,10,12.5,15])\n",
    "    plt.yticks([-20,-17.5,-15,-12.5,-10,-7.5,-5,-2.5])\n",
    "    \n",
    "    if filename:\n",
    "        plt.savefig(filename, format='png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tsne_plot_similar_words(\"\", \n",
    "                        keys, embeddings_en_2d, word_clusters, 1,\n",
    "                       'classic_plot.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
